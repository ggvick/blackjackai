{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f064adc0",
   "metadata": {},
   "source": [
    "# Blackjack RL Mega Notebook\n",
    "\n",
    "This mega notebook provisions a full reinforcement learning pipeline for blackjack, including environment setup, agent training, evaluation, interactive analysis, and validation. Run it top-to-bottom for a clean, reproducible workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c6bc2",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Kernel & Environment Diagnostics](#kernel--environment-diagnostics)\n",
    "2. [Project Setup](#project-setup)\n",
    "3. [Kernel Package Check](#kernel-package-check)\n",
    "4. [Module Import Sanity](#module-import-sanity)\n",
    "5. [Seeding Utilities](#seeding-utilities)\n",
    "6. [Compatibility Check](#compatibility-check)\n",
    "7. [Project Layout](#project-layout)\n",
    "8. [Configuration](#configuration)\n",
    "9. [Environment Preview](#environment-preview)\n",
    "10. [Training](#training)\n",
    "11. [Evaluation & Plots](#evaluation--plots)\n",
    "12. [Live Testing UI](#live-testing-ui)\n",
    "13. [Run Tests](#run-tests)\n",
    "14. [Notebook Validation](#notebook-validation)\n",
    "15. [Final Report](#final-report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75edb3ce",
   "metadata": {},
   "source": [
    "## Kernel & Environment Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0546a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def show_kernel_env():\n",
    "    print(\"Kernel Python:\", sys.executable)\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"--version\"], check=False)\n",
    "\n",
    "\n",
    "show_kernel_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56510179",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = \"https://github.com/ggvick/blackjackai.git\"\n",
    "WORK_ROOT = Path(\"proj\")\n",
    "REPO_DIR = WORK_ROOT / \"blackjackai\"\n",
    "RUNS_DIR = WORK_ROOT / \"runs\"\n",
    "NOTEBOOKS_DIR = WORK_ROOT / \"notebooks\"\n",
    "NOTEBOOK_SRC = Path.cwd() / \"notebooks\" / \"Blackjack_RL_Mega_Notebook.ipynb\"\n",
    "\n",
    "if WORK_ROOT.exists():\n",
    "    shutil.rmtree(WORK_ROOT)\n",
    "WORK_ROOT.mkdir(parents=True)\n",
    "\n",
    "subprocess.check_call([\"git\", \"clone\", REPO_URL, str(REPO_DIR)])\n",
    "\n",
    "RUNS_DIR.mkdir(exist_ok=True)\n",
    "NOTEBOOKS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "if NOTEBOOK_SRC.exists():\n",
    "    shutil.copy2(NOTEBOOK_SRC, NOTEBOOKS_DIR / NOTEBOOK_SRC.name)\n",
    "\n",
    "print(\"✅ Project root:\", WORK_ROOT.resolve())\n",
    "print(\"✅ Repo dir:\", REPO_DIR.resolve())\n",
    "print(\"✅ Runs dir:\", RUNS_DIR.resolve())\n",
    "print(\"✅ Notebooks dir:\", NOTEBOOKS_DIR.resolve())\n",
    "\n",
    "PROJECT_ROOT = REPO_DIR\n",
    "NOTEBOOK_PATH = NOTEBOOKS_DIR / NOTEBOOK_SRC.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea79eb",
   "metadata": {},
   "source": [
    "## Kernel Package Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy pandas matplotlib torch\n",
    "show_kernel_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01dcd1",
   "metadata": {},
   "source": [
    "## Module Import Sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25848ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = Path(\"proj/blackjackai\")\n",
    "if not REPO_DIR.exists():\n",
    "    raise FileNotFoundError(\"Expected repository at proj/blackjackai. Run the Project Setup cell first.\")\n",
    "\n",
    "module_parent = REPO_DIR\n",
    "resolved_parent = str(module_parent.resolve())\n",
    "if resolved_parent not in sys.path:\n",
    "    sys.path.insert(0, resolved_parent)\n",
    "\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "spec = importlib.util.find_spec(\"blackjack_env\")\n",
    "if spec is None:\n",
    "    raise ModuleNotFoundError(\"Could not locate 'blackjack_env'. Confirm that proj/blackjackai/blackjack_env/__init__.py exists.\")\n",
    "print(\"find_spec('blackjack_env'):\", bool(spec))\n",
    "\n",
    "from blackjack_env.env import EnvConfig\n",
    "from blackjack_env.utils import set_global_seeds\n",
    "\n",
    "print(\"✅ Imports OK:\", EnvConfig, set_global_seeds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41dd778",
   "metadata": {},
   "source": [
    "## Seeding Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2859a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    except Exception as exc:  # pragma: no cover\n",
    "        print(\"Torch seeding warning:\", exc)\n",
    "\n",
    "\n",
    "seed_everything(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9866c4e",
   "metadata": {},
   "source": [
    "## Compatibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "except Exception:  # pragma: no cover\n",
    "    torch = None\n",
    "\n",
    "rows = [\n",
    "    (\"Python\", sys.version.split()[0]),\n",
    "    (\"NumPy\", np.__version__),\n",
    "    (\"Pandas\", pd.__version__),\n",
    "    (\"Torch\", getattr(torch, '__version__', 'not installed')),\n",
    "]\n",
    "compat_df = pd.DataFrame(rows, columns=[\"Component\", \"Version\"])\n",
    "display(compat_df.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac20352",
   "metadata": {},
   "source": [
    "## Project Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89277f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "REPO_DIR = Path(\"proj/blackjackai\")\n",
    "RUNS_DIR = Path(\"proj\") / \"runs\"\n",
    "NOTEBOOKS_DIR = Path(\"proj\") / \"notebooks\"\n",
    "NOTEBOOK_PATH = NOTEBOOKS_DIR / \"Blackjack_RL_Mega_Notebook.ipynb\"\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    raise FileNotFoundError(\"Repository missing at proj/blackjackai. Re-run the Project Setup section.\")\n",
    "\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NOTEBOOKS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "path_rows = [\n",
    "    (\"Repository\", REPO_DIR.resolve()),\n",
    "    (\"Runs dir\", RUNS_DIR.resolve()),\n",
    "    (\"Notebooks dir\", NOTEBOOKS_DIR.resolve()),\n",
    "    (\"Active notebook\", NOTEBOOK_PATH.resolve() if NOTEBOOK_PATH.exists() else \"missing\"),\n",
    "]\n",
    "paths_df = pd.DataFrame(path_rows, columns=[\"Item\", \"Location\"])\n",
    "display(paths_df.style.hide(axis=\"index\"))\n",
    "\n",
    "PROJECT_ROOT = REPO_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c1c30",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76724e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from blackjack_env.env import EnvConfig\n",
    "from blackjack_env.utils import set_global_seeds\n",
    "\n",
    "LIGHT_MODE = os.environ.get(\"NBMAKE_ACTIVE\", \"0\") == \"1\"\n",
    "\n",
    "@dataclass\n",
    "class EnvUIConfig:\n",
    "    num_decks: int = 6\n",
    "    penetration: float = 0.75\n",
    "    bankroll_start: float = 100.0\n",
    "    bankroll_target: float = 200.0\n",
    "    min_bet: float = 5.0\n",
    "    max_bet: float = 100.0\n",
    "    bet_levels: int = 8\n",
    "    natural_payout: float = 1.5\n",
    "    hit_soft_17: bool = True\n",
    "    allow_surrender: bool = True\n",
    "    allow_double: bool = True\n",
    "    allow_split: bool = True\n",
    "    max_splits: int = 3\n",
    "    seed: int = 42\n",
    "\n",
    "@dataclass\n",
    "class AgentUIConfig:\n",
    "    buffer_size: int = 2048 if LIGHT_MODE else 50000\n",
    "    batch_size: int = 64 if LIGHT_MODE else 256\n",
    "    min_buffer_size: int = 64 if LIGHT_MODE else 2048\n",
    "    target_update_interval: int = 250 if LIGHT_MODE else 15000\n",
    "    epsilon_decay: int = 2000 if LIGHT_MODE else 1_200_000\n",
    "    use_noisy: bool = False\n",
    "    enable_c51: bool = True\n",
    "    use_amp: bool = False\n",
    "\n",
    "@dataclass\n",
    "class TrainUIConfig:\n",
    "    steps: int = 512 if LIGHT_MODE else 20_000\n",
    "    log_interval: int = 128 if LIGHT_MODE else 2000\n",
    "    eval_hands: int = 200 if LIGHT_MODE else 10_000\n",
    "\n",
    "CONFIG_STATE = {\n",
    "    \"env\": EnvUIConfig(),\n",
    "    \"agent\": AgentUIConfig(),\n",
    "    \"train\": TrainUIConfig(),\n",
    "    \"paths\": {\"project_root\": str(PROJECT_ROOT), \"runs\": str(Path(\"proj\") / \"runs\"), \"notebooks\": str(Path(\"proj\") / \"notebooks\")},\n",
    "}\n",
    "\n",
    "seed_table = pd.DataFrame([{\"Component\": \"Global Seed\", \"Value\": CONFIG_STATE[\"env\"].seed}])\n",
    "display(seed_table.style.hide(axis=\"index\"))\n",
    "\n",
    "set_global_seeds(CONFIG_STATE[\"env\"].seed)\n",
    "\n",
    "style = {\"description_width\": \"150px\"}\n",
    "\n",
    "env_widgets = {\n",
    "    \"num_decks\": widgets.IntSlider(value=CONFIG_STATE[\"env\"].num_decks, min=1, max=8, description=\"Decks\", style=style),\n",
    "    \"penetration\": widgets.FloatSlider(value=CONFIG_STATE[\"env\"].penetration, min=0.1, max=0.95, step=0.05, description=\"Penetration\", style=style),\n",
    "    \"bankroll_start\": widgets.FloatText(value=CONFIG_STATE[\"env\"].bankroll_start, description=\"Bankroll\", style=style),\n",
    "    \"bankroll_target\": widgets.FloatText(value=CONFIG_STATE[\"env\"].bankroll_target, description=\"Target\", style=style),\n",
    "    \"min_bet\": widgets.FloatText(value=CONFIG_STATE[\"env\"].min_bet, description=\"Min Bet\", style=style),\n",
    "    \"max_bet\": widgets.FloatText(value=CONFIG_STATE[\"env\"].max_bet, description=\"Max Bet\", style=style),\n",
    "    \"bet_levels\": widgets.IntSlider(value=CONFIG_STATE[\"env\"].bet_levels, min=1, max=16, description=\"Bet Levels\", style=style),\n",
    "    \"seed\": widgets.IntText(value=CONFIG_STATE[\"env\"].seed, description=\"Seed\", style=style),\n",
    "}\n",
    "\n",
    "agent_widgets = {\n",
    "    \"buffer_size\": widgets.IntSlider(value=CONFIG_STATE[\"agent\"].buffer_size, min=512, max=200000, step=512, description=\"Buffer\", style=style),\n",
    "    \"batch_size\": widgets.IntSlider(value=CONFIG_STATE[\"agent\"].batch_size, min=32, max=1024, step=32, description=\"Batch\", style=style),\n",
    "    \"min_buffer_size\": widgets.IntSlider(value=CONFIG_STATE[\"agent\"].min_buffer_size, min=32, max=5000, step=32, description=\"Min Buffer\", style=style),\n",
    "    \"target_update_interval\": widgets.IntSlider(value=CONFIG_STATE[\"agent\"].target_update_interval, min=100, max=20000, step=100, description=\"Target Update\", style=style),\n",
    "    \"epsilon_decay\": widgets.IntSlider(value=CONFIG_STATE[\"agent\"].epsilon_decay, min=500, max=1_500_000, step=500, description=\"Epsilon Decay\", style=style),\n",
    "    \"use_noisy\": widgets.Checkbox(value=CONFIG_STATE[\"agent\"].use_noisy, description=\"Use Noisy\"),\n",
    "    \"enable_c51\": widgets.Checkbox(value=CONFIG_STATE[\"agent\"].enable_c51, description=\"Enable C51\"),\n",
    "    \"use_amp\": widgets.Checkbox(value=CONFIG_STATE[\"agent\"].use_amp, description=\"Use AMP\"),\n",
    "}\n",
    "\n",
    "train_widgets = {\n",
    "    \"steps\": widgets.IntSlider(value=CONFIG_STATE[\"train\"].steps, min=128, max=20000, step=128, description=\"Train Steps\", style=style),\n",
    "    \"log_interval\": widgets.IntSlider(value=CONFIG_STATE[\"train\"].log_interval, min=32, max=5000, step=32, description=\"Log Interval\", style=style),\n",
    "    \"eval_hands\": widgets.IntSlider(value=CONFIG_STATE[\"train\"].eval_hands, min=100, max=200000, step=100, description=\"Eval Hands\", style=style),\n",
    "}\n",
    "\n",
    "config_output = widgets.Output()\n",
    "\n",
    "\n",
    "def _as_env_config() -> EnvConfig:\n",
    "    return EnvConfig(\n",
    "        num_decks=env_widgets[\"num_decks\"].value,\n",
    "        penetration=env_widgets[\"penetration\"].value,\n",
    "        bankroll_start=env_widgets[\"bankroll_start\"].value,\n",
    "        bankroll_target=env_widgets[\"bankroll_target\"].value,\n",
    "        min_bet=env_widgets[\"min_bet\"].value,\n",
    "        max_bet=env_widgets[\"max_bet\"].value,\n",
    "        bet_levels=env_widgets[\"bet_levels\"].value,\n",
    "        seed=env_widgets[\"seed\"].value,\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_configs(_=None):\n",
    "    CONFIG_STATE[\"env\"] = EnvUIConfig(\n",
    "        num_decks=env_widgets[\"num_decks\"].value,\n",
    "        penetration=env_widgets[\"penetration\"].value,\n",
    "        bankroll_start=env_widgets[\"bankroll_start\"].value,\n",
    "        bankroll_target=env_widgets[\"bankroll_target\"].value,\n",
    "        min_bet=env_widgets[\"min_bet\"].value,\n",
    "        max_bet=env_widgets[\"max_bet\"].value,\n",
    "        bet_levels=env_widgets[\"bet_levels\"].value,\n",
    "        seed=env_widgets[\"seed\"].value,\n",
    "    )\n",
    "    CONFIG_STATE[\"agent\"] = AgentUIConfig(\n",
    "        buffer_size=agent_widgets[\"buffer_size\"].value,\n",
    "        batch_size=agent_widgets[\"batch_size\"].value,\n",
    "        min_buffer_size=agent_widgets[\"min_buffer_size\"].value,\n",
    "        target_update_interval=agent_widgets[\"target_update_interval\"].value,\n",
    "        epsilon_decay=agent_widgets[\"epsilon_decay\"].value,\n",
    "        use_noisy=agent_widgets[\"use_noisy\"].value,\n",
    "        enable_c51=agent_widgets[\"enable_c51\"].value,\n",
    "        use_amp=agent_widgets[\"use_amp\"].value,\n",
    "    )\n",
    "    CONFIG_STATE[\"train\"] = TrainUIConfig(\n",
    "        steps=train_widgets[\"steps\"].value,\n",
    "        log_interval=train_widgets[\"log_interval\"].value,\n",
    "        eval_hands=train_widgets[\"eval_hands\"].value,\n",
    "    )\n",
    "    set_global_seeds(CONFIG_STATE[\"env\"].seed)\n",
    "    cfg_json = json.dumps({\n",
    "        \"env\": asdict(CONFIG_STATE[\"env\"]),\n",
    "        \"agent\": asdict(CONFIG_STATE[\"agent\"]),\n",
    "        \"train\": asdict(CONFIG_STATE[\"train\"]),\n",
    "        \"paths\": CONFIG_STATE[\"paths\"],\n",
    "    }, indent=2)\n",
    "    with config_output:\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<pre style='font-size:12px'>{cfg_json}</pre>\"))\n",
    "\n",
    "\n",
    "apply_button = widgets.Button(description=\"Apply Config\", button_style=\"success\")\n",
    "apply_button.on_click(apply_configs)\n",
    "\n",
    "copy_button = widgets.Button(description=\"Copy Config\", button_style=\"info\")\n",
    "\n",
    "\n",
    "def copy_to_clipboard(_):\n",
    "    cfg_json = json.dumps({\n",
    "        \"env\": asdict(CONFIG_STATE[\"env\"]),\n",
    "        \"agent\": asdict(CONFIG_STATE[\"agent\"]),\n",
    "        \"train\": asdict(CONFIG_STATE[\"train\"]),\n",
    "        \"paths\": CONFIG_STATE[\"paths\"],\n",
    "    }, indent=2)\n",
    "    with config_output:\n",
    "        display(HTML(f\"<script>navigator.clipboard.writeText({json.dumps(cfg_json)});</script>\"))\n",
    "    params_path = Path(CONFIG_STATE[\"paths\"][\"runs\"]) / \"config_snapshot.json\"\n",
    "    params_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    params_path.write_text(cfg_json)\n",
    "\n",
    "\n",
    "copy_button.on_click(copy_to_clipboard)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Environment</b>\"),\n",
    "    widgets.HBox(list(env_widgets.values())),\n",
    "    widgets.HTML(\"<b>Agent</b>\"),\n",
    "    widgets.HBox(list(agent_widgets.values())),\n",
    "    widgets.HTML(\"<b>Training</b>\"),\n",
    "    widgets.HBox(list(train_widgets.values())),\n",
    "    widgets.HBox([apply_button, copy_button]),\n",
    "    config_output,\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "apply_configs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427500e4",
   "metadata": {},
   "source": [
    "## Environment Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a99043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from blackjack_env.env import BlackjackEnv\n",
    "from blackjack_env.masking import ACTIONS\n",
    "\n",
    "preview_env = BlackjackEnv(EnvConfig(**asdict(CONFIG_STATE[\"env\"])) )\n",
    "obs = preview_env.reset()\n",
    "obs, _, _, _ = preview_env.step({\"bet\": 0})\n",
    "mask = preview_env.available_actions()\n",
    "\n",
    "obs_series = pd.Series(obs, name=\"feature\")\n",
    "mask_df = pd.DataFrame({\"action\": ACTIONS, \"legal\": mask})\n",
    "\n",
    "display(obs_series.to_frame(\"value\").head(20))\n",
    "display(mask_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d98bc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf4d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from agents.dqn_rainbow import AgentConfig as RainbowAgentConfig, RainbowDQNAgent\n",
    "\n",
    "train_env = BlackjackEnv(EnvConfig(**asdict(CONFIG_STATE[\"env\"])) )\n",
    "agent_cfg_kwargs = {\n",
    "    \"buffer_size\": CONFIG_STATE[\"agent\"].buffer_size,\n",
    "    \"batch_size\": CONFIG_STATE[\"agent\"].batch_size,\n",
    "    \"min_buffer_size\": CONFIG_STATE[\"agent\"].min_buffer_size,\n",
    "    \"target_update_interval\": CONFIG_STATE[\"agent\"].target_update_interval,\n",
    "    \"epsilon_decay\": CONFIG_STATE[\"agent\"].epsilon_decay,\n",
    "    \"use_noisy\": CONFIG_STATE[\"agent\"].use_noisy,\n",
    "    \"enable_c51\": CONFIG_STATE[\"agent\"].enable_c51,\n",
    "    \"use_amp\": CONFIG_STATE[\"agent\"].use_amp,\n",
    "}\n",
    "\n",
    "agent_config = RainbowAgentConfig(\n",
    "    observation_dim=train_env.observation_space.size,\n",
    "    bet_actions=train_env.config.bet_levels,\n",
    "    **agent_cfg_kwargs,\n",
    ")\n",
    "\n",
    "agent = RainbowDQNAgent(agent_config)\n",
    "run_dir = Path(CONFIG_STATE[\"paths\"][\"runs\"]) / datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "(run_dir / \"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metrics_log = []\n",
    "\n",
    "\n",
    "def training_callback(step, metrics):\n",
    "    metrics_log.append({\"step\": agent.global_step, **metrics})\n",
    "    with training_output:\n",
    "        clear_output(wait=True)\n",
    "        df = pd.DataFrame(metrics_log)\n",
    "        if not df.empty:\n",
    "            display(df.tail(10))\n",
    "\n",
    "\n",
    "training_output = widgets.Output()\n",
    "display(training_output)\n",
    "\n",
    "metrics = agent.train(train_env, steps=CONFIG_STATE[\"train\"].steps, callback=training_callback)\n",
    "\n",
    "metrics_log.append({\"step\": agent.global_step, **metrics})\n",
    "metrics_df = pd.DataFrame(metrics_log)\n",
    "metrics_path = run_dir / \"metrics.json\"\n",
    "metrics_path.write_text(metrics_df.to_json(orient=\"records\", indent=2))\n",
    "\n",
    "config_path = run_dir / \"params.json\"\n",
    "config_payload = {\n",
    "    \"env\": asdict(CONFIG_STATE[\"env\"]),\n",
    "    \"agent\": asdict(CONFIG_STATE[\"agent\"]),\n",
    "    \"train\": asdict(CONFIG_STATE[\"train\"]),\n",
    "}\n",
    "config_path.write_text(json.dumps(config_payload, indent=2))\n",
    "\n",
    "checkpoint_path = run_dir / \"checkpoints\" / \"final.pt\"\n",
    "torch.save(agent.online_net.state_dict(), checkpoint_path)\n",
    "\n",
    "TRAINING_STATE = {\n",
    "    \"agent\": agent,\n",
    "    \"env_config\": EnvConfig(**asdict(CONFIG_STATE[\"env\"])),\n",
    "    \"run_dir\": run_dir,\n",
    "    \"metrics_df\": metrics_df,\n",
    "}\n",
    "\n",
    "metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c0368",
   "metadata": {},
   "source": [
    "## Evaluation & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from agents.eval import evaluate_policy\n",
    "from blackjack_env.basic_strategy import BasicStrategyPolicy\n",
    "from blackjack_env.masking import ACTIONS\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "\n",
    "def collect_decisions(agent, env_config, hands=200):\n",
    "    env = BlackjackEnv(env_config)\n",
    "    env.reset()\n",
    "    decisions = []\n",
    "    while len(decisions) < hands:\n",
    "        if env.state.stage == \"bet\":\n",
    "            env.step({\"bet\": 0})\n",
    "            continue\n",
    "        mask = env.available_actions()\n",
    "        obs = env._current_observation()\n",
    "        action, q_values = agent.act_play(obs, mask)\n",
    "        bankroll_before = env.state.bankroll\n",
    "        _, reward, done, info = env.step(action)\n",
    "        bankroll_after = env.state.bankroll\n",
    "        if info.get(\"round_complete\"):\n",
    "            decisions.append({\n",
    "                \"hand\": len(decisions),\n",
    "                \"action\": ACTIONS[action],\n",
    "                \"reward\": reward,\n",
    "                \"bankroll_before\": bankroll_before,\n",
    "                \"bankroll_after\": bankroll_after,\n",
    "                \"running_count\": env.state.count_state.running_count,\n",
    "            })\n",
    "        if done:\n",
    "            env.reset()\n",
    "    return pd.DataFrame(decisions)\n",
    "\n",
    "\n",
    "agent_decisions = collect_decisions(TRAINING_STATE[\"agent\"], TRAINING_STATE[\"env_config\"], hands=min(CONFIG_STATE[\"train\"].eval_hands, 1000))\n",
    "agent_decisions_path = TRAINING_STATE[\"run_dir\"] / \"decisions.csv\"\n",
    "agent_decisions.to_csv(agent_decisions_path, index=False)\n",
    "agent_decisions.to_json(TRAINING_STATE[\"run_dir\"] / \"decisions.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "basic_policy = BasicStrategyPolicy()\n",
    "\n",
    "def basic_policy_fn(dealer_upcard, hand, mask):\n",
    "    return basic_policy.act(dealer_upcard, hand, mask)\n",
    "\n",
    "\n",
    "def agent_policy_fn(dealer_upcard, hand, mask):\n",
    "    env = evaluation_env\n",
    "    obs = env._current_observation()\n",
    "    action, _ = TRAINING_STATE[\"agent\"].act_play(obs, mask)\n",
    "    return action\n",
    "\n",
    "\n",
    "evaluation_env = BlackjackEnv(TRAINING_STATE[\"env_config\"])\n",
    "agent_eval = evaluate_policy(evaluation_env, agent_policy_fn, num_hands=min(CONFIG_STATE[\"train\"].eval_hands, 2000))\n",
    "baseline_env = BlackjackEnv(TRAINING_STATE[\"env_config\"])\n",
    "basic_eval = evaluate_policy(baseline_env, basic_policy_fn, num_hands=min(CONFIG_STATE[\"train\"].eval_hands, 2000))\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\"Policy\": \"Rainbow Agent\", \"EV/100\": agent_eval.ev_per_100, \"Win\": agent_eval.win_rate, \"Loss\": agent_eval.loss_rate, \"Push\": agent_eval.push_rate},\n",
    "    {\"Policy\": \"Basic Strategy\", \"EV/100\": basic_eval.ev_per_100, \"Win\": basic_eval.win_rate, \"Loss\": basic_eval.loss_rate, \"Push\": basic_eval.push_rate},\n",
    "])\n",
    "\n",
    "display(summary_df)\n",
    "\n",
    "try:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    agent_decisions.set_index(\"hand\")[\"bankroll_after\"].plot(ax=axes[0], title=\"Bankroll\")\n",
    "    agent_decisions.groupby(\"action\")[\"action\"].count().plot(kind=\"bar\", ax=axes[1], title=\"Action Frequency\")\n",
    "    agent_decisions[\"running_count\"].hist(ax=axes[2])\n",
    "    axes[2].set_title(\"Running Count Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plot_path = TRAINING_STATE[\"run_dir\"] / \"performance.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "except Exception as exc:  # pragma: no cover\n",
    "    display(HTML(f\"<p>No plots generated: {exc}</p>\"))\n",
    "\n",
    "summary_text = f'''EV/100: {agent_eval.ev_per_100:.3f} (CI [{agent_eval.ci_low:.3f}, {agent_eval.ci_high:.3f}])\n",
    "Win Rate: {agent_eval.win_rate:.3f}\n",
    "Loss Rate: {agent_eval.loss_rate:.3f}\n",
    "Push Rate: {agent_eval.push_rate:.3f}\n",
    "Baseline EV/100: {basic_eval.ev_per_100:.3f}\n",
    "'''\n",
    "(TRAINING_STATE[\"run_dir\"] / \"summary_llm.txt\").write_text(summary_text)\n",
    "\n",
    "summary_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be6a01",
   "metadata": {},
   "source": [
    "## Live Testing UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96423c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "live_env = BlackjackEnv(TRAINING_STATE[\"env_config\"])\n",
    "live_env.reset()\n",
    "live_env.step({\"bet\": 0})\n",
    "\n",
    "live_output = widgets.Output()\n",
    "\n",
    "agent_dropdown = widgets.Dropdown(options=[\"Rainbow Agent\", \"Basic Strategy\"], description=\"Agent\")\n",
    "step_button = widgets.Button(description=\"Step\", button_style=\"primary\")\n",
    "auto_toggle = widgets.ToggleButton(description=\"Auto-Play\", value=False)\n",
    "reset_button = widgets.Button(description=\"Reset Episode\", button_style=\"warning\")\n",
    "delay_slider = widgets.IntSlider(value=200, min=0, max=1000, step=50, description=\"Delay (ms)\")\n",
    "\n",
    "basic_policy = BasicStrategyPolicy()\n",
    "\n",
    "\n",
    "def render_state(reward=0.0, done=False):\n",
    "    with live_output:\n",
    "        clear_output(wait=True)\n",
    "        dealer_card = live_env.state.dealer_hand.cards[0] if live_env.state.dealer_hand else None\n",
    "        player_hand = live_env.state.player_hands[live_env.state.current_hand_index] if live_env.state.player_hands else None\n",
    "        html = f'''\n",
    "        <div style='border:1px solid #ccc;padding:8px;'>\n",
    "            <p><b>Stage:</b> {live_env.state.stage}</p>\n",
    "            <p><b>Dealer Upcard:</b> {dealer_card}</p>\n",
    "            <p><b>Player Hand:</b> {player_hand.cards if player_hand else []} (total {player_hand.total if player_hand else 0})</p>\n",
    "            <p><b>Bankroll:</b> {live_env.state.bankroll:.2f}</p>\n",
    "            <p><b>Reward:</b> {reward:.2f}</p>\n",
    "            <p><b>Done:</b> {done}</p>\n",
    "        </div>\n",
    "        '''\n",
    "        display(HTML(html))\n",
    "\n",
    "\n",
    "def choose_action():\n",
    "    mask = live_env.available_actions()\n",
    "    if mask.sum() == 0:\n",
    "        return None\n",
    "    if agent_dropdown.value == \"Basic Strategy\":\n",
    "        return basic_policy.act(live_env.state.dealer_hand.cards[0], live_env.state.player_hands[live_env.state.current_hand_index], mask)\n",
    "    obs = live_env._current_observation()\n",
    "    action, _ = TRAINING_STATE[\"agent\"].act_play(obs, mask)\n",
    "    return action\n",
    "\n",
    "\n",
    "def step_once(_=None):\n",
    "    if live_env.state.stage == \"bet\":\n",
    "        live_env.step({\"bet\": 0})\n",
    "    action = choose_action()\n",
    "    reward = 0.0\n",
    "    done = False\n",
    "    if action is not None:\n",
    "        _, reward, done, info = live_env.step(action)\n",
    "        if done:\n",
    "            live_env.reset()\n",
    "            live_env.step({\"bet\": 0})\n",
    "    render_state(reward=reward, done=done)\n",
    "    if auto_toggle.value and not done:\n",
    "        time.sleep(delay_slider.value / 1000.0)\n",
    "        step_once()\n",
    "\n",
    "\n",
    "def reset_episode(_=None):\n",
    "    live_env.reset()\n",
    "    live_env.step({\"bet\": 0})\n",
    "    render_state()\n",
    "\n",
    "\n",
    "def handle_auto(change):\n",
    "    if change[\"new\"]:\n",
    "        step_once()\n",
    "\n",
    "\n",
    "step_button.on_click(step_once)\n",
    "reset_button.on_click(reset_episode)\n",
    "auto_toggle.observe(handle_auto, names=\"value\")\n",
    "\n",
    "controls = widgets.HBox([step_button, auto_toggle, reset_button, agent_dropdown, delay_slider])\n",
    "display(widgets.VBox([controls, live_output]))\n",
    "render_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c6304",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a87d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "import subprocess\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "start = time.time()\n",
    "result = subprocess.run([sys.executable, \"-m\", \"pytest\", \"-q\", \"--disable-warnings\", \"--maxfail=1\"], cwd=Path(\"proj/blackjackai\"), capture_output=True, text=True)\n",
    "duration = time.time() - start\n",
    "status = \"Pass\" if result.returncode == 0 else \"Fail\"\n",
    "summary = pd.DataFrame([\n",
    "    {\"Command\": \"pytest -q --disable-warnings --maxfail=1\", \"Status\": status, \"Duration (s)\": f\"{duration:.2f}\"}\n",
    "])\n",
    "if status == \"Fail\":\n",
    "    display(HTML(f\"<pre>{result.stdout}\\n{result.stderr}</pre>\"))\n",
    "styled_summary = summary.style.applymap(lambda v: \"background-color:#c8e6c9\" if v == \"Pass\" else \"background-color:#ffcdd2\", subset=[\"Status\"])\n",
    "display(styled_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab2163",
   "metadata": {},
   "source": [
    "## Notebook Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "validation_env = dict(os.environ)\n",
    "validation_env.setdefault(\"NBMAKE_ACTIVE\", \"1\")\n",
    "validation_result = subprocess.run([sys.executable, \"-m\", \"pytest\", \"--nbmake\", (Path(\"proj\") / \"notebooks\" / \"Blackjack_RL_Mega_Notebook.ipynb\").name], cwd=Path(\"proj\") / \"notebooks\", capture_output=True, text=True, env=validation_env)\n",
    "validation_status = \"Pass\" if validation_result.returncode == 0 else \"Fail\"\n",
    "validation_df = pd.DataFrame([\n",
    "    {\"Command\": f\"pytest --nbmake {(Path(\"proj\") / \"notebooks\" / \"Blackjack_RL_Mega_Notebook.ipynb\").name}\", \"Status\": validation_status}\n",
    "])\n",
    "if validation_status == \"Fail\":\n",
    "    display(HTML(f\"<pre>{validation_result.stdout}\\n{validation_result.stderr}</pre>\"))\n",
    "styled_validation = validation_df.style.applymap(lambda v: \"background-color:#c8e6c9\" if v == \"Pass\" else \"background-color:#ffcdd2\", subset=[\"Status\"])\n",
    "display(styled_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f56773",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ee6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display\n",
    "import subprocess\n",
    "commands = [\n",
    "    (\"ruff --version\", [\"ruff\", \"--version\"]),\n",
    "    (\"black --version\", [\"black\", \"--version\"]),\n",
    "    (\"pytest -q --disable-warnings --maxfail=1\", [sys.executable, \"-m\", \"pytest\", \"-q\", \"--disable-warnings\", \"--maxfail=1\"]),\n",
    "]\n",
    "rows = []\n",
    "for label, cmd in commands:\n",
    "    try:\n",
    "        result = subprocess.run(cmd, cwd=Path(\"proj/blackjackai\"), capture_output=True, text=True, check=True)\n",
    "        rows.append({\"Command\": label, \"Status\": \"Pass\"})\n",
    "    except FileNotFoundError:\n",
    "        pkg = cmd[0]\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "        retry = subprocess.run(cmd, cwd=Path(\"proj/blackjackai\"), capture_output=True, text=True, check=True)\n",
    "        rows.append({\"Command\": label, \"Status\": \"Pass\"})\n",
    "    except subprocess.CalledProcessError as exc:\n",
    "        rows.append({\"Command\": label, \"Status\": \"Fail\", \"Output\": exc.stdout + exc.stderr})\n",
    "\n",
    "report_df = pd.DataFrame(rows)\n",
    "styled_report = report_df.style.applymap(lambda v: \"background-color:#c8e6c9\" if v == \"Pass\" else \"background-color:#ffcdd2\", subset=[\"Status\"])\n",
    "display(styled_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
