{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78dfac70",
   "metadata": {},
   "source": [
    "\n",
    "# Blackjack AI Training & Evaluation\n",
    "\n",
    "This notebook trains and evaluates Blackjack reinforcement learning agents. It is designed to run top-to-bottom in Google Colab or Jupyter.\n",
    "\n",
    "**Workflow overview**\n",
    "1. Run the setup cell to install/runtime-check dependencies and configure the notebook.\n",
    "2. Execute the smoke tests to validate the Blackjack environment and utilities.\n",
    "3. Train the DQN agent (vectorised env) and track learning curves.\n",
    "4. Evaluate the trained policy against a basic-strategy counting baseline, generating plots and CSV artifacts.\n",
    "\n",
    "Artifacts are saved under `./outputs` with subfolders for models, metrics, and plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "REQUIRED_PACKAGES = {\n",
    "    \"torch\": \"torch\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"tqdm\": \"tqdm\",\n",
    "}\n",
    "\n",
    "for module_name, install_name in REQUIRED_PACKAGES.items():\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {install_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", install_name])\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import torch\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "OUTPUT_DIR = ROOT / \"outputs\"\n",
    "for sub in [OUTPUT_DIR, OUTPUT_DIR / \"models\", OUTPUT_DIR / \"plots\", OUTPUT_DIR / \"metrics\"]:\n",
    "    sub.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Outputs directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from blackjackai_rl.device import detect_torch_device\n",
    "from blackjackai_rl.utils import ensure_dir, set_global_seed, to_json\n",
    "from blackjackai_rl.env import BlackjackEnvConfig\n",
    "from blackjackai_rl.agents import DQNAgent, DQNConfig\n",
    "from blackjackai_rl.training import train_dqn\n",
    "from blackjackai_rl.evaluation import (\n",
    "    compare_to_baseline,\n",
    "    evaluate_policy,\n",
    "    plot_evaluation_results,\n",
    "    plot_training_curves,\n",
    "    save_hand_records,\n",
    ")\n",
    "from blackjackai_rl.tests import run_all_tests\n",
    "\n",
    "DEVICE = detect_torch_device()\n",
    "print(f\"Using device: {DEVICE.device}\")\n",
    "set_global_seed(42)\n",
    "BASE_OUTPUT = ensure_dir(\"outputs\")\n",
    "ensure_dir(BASE_OUTPUT / \"plots\")\n",
    "ensure_dir(BASE_OUTPUT / \"metrics\")\n",
    "ensure_dir(BASE_OUTPUT / \"models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65daa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = run_all_tests()\n",
    "for result in results:\n",
    "    status = \"PASS\" if result.passed else \"FAIL\"\n",
    "    message = f\"{status} :: {result.name}\"\n",
    "    if result.details:\n",
    "        message += f\" | {result.details}\"\n",
    "    print(message)\n",
    "assert all(r.passed for r in results), \"One or more smoke tests failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_steps = 20000\n",
    "vector_envs = 32\n",
    "log_interval = 1000\n",
    "evaluation_hands = 4000\n",
    "\n",
    "env_config = BlackjackEnvConfig(\n",
    "    num_decks=6,\n",
    "    penetration=0.8,\n",
    "    natural_payout=1.5,\n",
    "    hit_soft_17=False,\n",
    "    min_bet=1.0,\n",
    "    max_bet=8.0,\n",
    "    bankroll=100.0,\n",
    "    bankroll_stop_loss=0.0,\n",
    "    bankroll_target=200.0,\n",
    "    allow_surrender=True,\n",
    "    allow_double=True,\n",
    "    allow_split=True,\n",
    "    max_splits=1,\n",
    "    reward_shaping=True,\n",
    "    shaping_stop_step=60000,\n",
    ")\n",
    "\n",
    "agent_config = DQNConfig(\n",
    "    state_dim=12,\n",
    "    num_actions=5,\n",
    "    hidden_sizes=(256, 256),\n",
    "    gamma=0.99,\n",
    "    lr=5e-4,\n",
    "    epsilon_start=1.0,\n",
    "    epsilon_final=0.05,\n",
    "    epsilon_decay=200000,\n",
    "    batch_size=512,\n",
    "    buffer_size=200000,\n",
    "    min_buffer_size=4000,\n",
    "    target_update_interval=2000,\n",
    "    tau=0.01,\n",
    "    device=DEVICE.device,\n",
    ")\n",
    "\n",
    "print(\"Training configuration ready\")\n",
    "print(env_config)\n",
    "print(agent_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50128cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_history = train_dqn(\n",
    "    env_config=env_config,\n",
    "    agent_config=agent_config,\n",
    "    total_steps=training_steps,\n",
    "    vector_envs=vector_envs,\n",
    "    log_interval=log_interval,\n",
    "    output_dir=BASE_OUTPUT,\n",
    ")\n",
    "\n",
    "best_model_path = Path(training_history[\"best_model_path\"])\n",
    "print(f\"Best checkpoint: {best_model_path}\")\n",
    "print(f\"Timings: {[asdict(t) for t in training_history['timings']]}\")\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"reward\": training_history[\"reward_history\"],\n",
    "    \"epsilon\": training_history[\"epsilon_history\"],\n",
    "})\n",
    "metrics_csv = BASE_OUTPUT / \"metrics\" / \"training_batch_metrics.csv\"\n",
    "metrics_df.to_csv(metrics_csv, index_label=\"batch\")\n",
    "print(f\"Saved batch metrics to {metrics_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_paths = plot_training_curves(training_history, BASE_OUTPUT)\n",
    "print(\"Training plots:\")\n",
    "for name, path in plot_paths.items():\n",
    "    print(f\"  {name}: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_agent = DQNAgent(agent_config)\n",
    "trained_agent.load(str(best_model_path), map_location=DEVICE.device)\n",
    "\n",
    "comparison = compare_to_baseline(env_config, trained_agent, num_hands=evaluation_hands)\n",
    "trained_eval = comparison[\"trained\"]\n",
    "baseline_eval = comparison[\"baseline\"]\n",
    "\n",
    "trained_records = pd.DataFrame([asdict(record) for record in trained_eval[\"hand_records\"]])\n",
    "baseline_records = pd.DataFrame([asdict(record) for record in baseline_eval[\"hand_records\"]])\n",
    "\n",
    "trained_records_path = BASE_OUTPUT / \"metrics\" / \"trained_hand_history.csv\"\n",
    "baseline_records_path = BASE_OUTPUT / \"metrics\" / \"baseline_hand_history.csv\"\n",
    "trained_records.to_csv(trained_records_path, index=False)\n",
    "baseline_records.to_csv(baseline_records_path, index=False)\n",
    "print(f\"Saved trained hand history to {trained_records_path}\")\n",
    "print(f\"Saved baseline hand history to {baseline_records_path}\")\n",
    "\n",
    "summary_json = {\n",
    "    \"trained\": asdict(trained_eval[\"summary\"]),\n",
    "    \"baseline\": asdict(baseline_eval[\"summary\"]),\n",
    "    \"expected_value_gain\": comparison[\"expected_value_gain\"],\n",
    "}\n",
    "summary_path = BASE_OUTPUT / \"metrics\" / \"evaluation_summary.json\"\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as handle:\n",
    "    json.dump(summary_json, handle, indent=2)\n",
    "print(f\"Summary saved to {summary_path}\")\n",
    "\n",
    "plot_eval_paths = plot_evaluation_results(trained_eval[\"hand_records\"], BASE_OUTPUT)\n",
    "print(\"Evaluation plots:\")\n",
    "for name, path in plot_eval_paths.items():\n",
    "    print(f\"  {name}: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7bac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_summary = comparison[\"trained\"][\"summary\"]\n",
    "baseline_summary = comparison[\"baseline\"][\"summary\"]\n",
    "print(\"Trained agent summary:\")\n",
    "print(trained_summary)\n",
    "print(\"\n",
    "Baseline summary:\")\n",
    "print(baseline_summary)\n",
    "print(\"\n",
    "Expected value gain per hand:\", comparison[\"expected_value_gain\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "artifacts = {\n",
    "    \"best_model\": str(best_model_path),\n",
    "    \"final_model\": str(Path(BASE_OUTPUT) / \"models\" / \"final_dqn.pt\"),\n",
    "    \"training_metrics\": str(metrics_csv),\n",
    "    \"evaluation_summary\": str(BASE_OUTPUT / \"metrics\" / \"evaluation_summary.json\"),\n",
    "}\n",
    "artifacts.update(plot_paths)\n",
    "artifacts.update(plot_eval_paths)\n",
    "print(\"âœ… Training complete | Eval done | Plots saved to ./outputs | Best model:\", best_model_path)\n",
    "pprint(artifacts)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
