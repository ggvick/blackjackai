{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357b732a",
   "metadata": {},
   "source": [
    "# Blackjack Rainbow DQN Notebook\n",
    "\n",
    "![Tests](https://img.shields.io/badge/tests-pytest-blue) ![Coverage](https://img.shields.io/badge/coverage-summary-green)\n",
    "\n",
    "> End-to-end pipeline for training and evaluating a Rainbow DQN Blackjack agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae967c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Run All\n",
    "RUN_ALL = True\n",
    "PIPELINE_STEPS = []\n",
    "TRAINING_RESULTS = {}\n",
    "EVALUATION_RESULTS = {}\n",
    "\n",
    "def register_step(func):\n",
    "    PIPELINE_STEPS.append(func)\n",
    "    return func\n",
    "\n",
    "\n",
    "def run_all_pipeline():\n",
    "    from time import perf_counter\n",
    "    start = perf_counter()\n",
    "    for step in PIPELINE_STEPS:\n",
    "        print(f\"‚ñ∂Ô∏è {step.__name__}\")\n",
    "        step()\n",
    "    print(f\"‚úÖ Pipeline finished in {perf_counter() - start:.2f}s\")\n",
    "\n",
    "if not RUN_ALL:\n",
    "    print(\"Set `RUN_ALL = True` in this cell to execute the entire notebook automatically.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b05078",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The following dataclasses expose the configuration used by the environment, agent, and training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea045dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "@dataclass\n",
    "class NotebookEnvConfig:\n",
    "    num_decks: int = 6\n",
    "    penetration: float = 0.8\n",
    "    natural_payout: float = 1.5\n",
    "    hit_soft_17: bool = False\n",
    "    min_bet: float = 1.0\n",
    "    max_bet: float = 8.0\n",
    "    bankroll: float = 100.0\n",
    "    bankroll_stop_loss: float = 0.0\n",
    "    bankroll_target: float = 200.0\n",
    "    allow_surrender: bool = True\n",
    "    allow_double: bool = True\n",
    "    allow_split: bool = True\n",
    "    max_splits: int = 1\n",
    "    reward_shaping: bool = True\n",
    "    shaping_stop_step: int = 60_000\n",
    "    penetration_reset: bool = True\n",
    "    bet_actions: int = 8\n",
    "    reward_clip: float | None = 5.0\n",
    "    seed: int = 123\n",
    "\n",
    "    def to_env(self):\n",
    "        from blackjackai_rl.env import BlackjackEnvConfig\n",
    "        return BlackjackEnvConfig(**asdict(self))\n",
    "\n",
    "@dataclass\n",
    "class NotebookAgentConfig:\n",
    "    state_dim: int = 36\n",
    "    num_actions: int = 5\n",
    "    bet_actions: int = 8\n",
    "    hidden_sizes: Tuple[int, int] = (512, 512)\n",
    "    gamma: float = 0.99\n",
    "    lr: float = 3e-4\n",
    "    bet_lr: float = 3e-4\n",
    "    epsilon_start: float = 1.0\n",
    "    epsilon_final: float = 0.05\n",
    "    epsilon_decay: int = 1_200_000\n",
    "    batch_size: int = 512\n",
    "    buffer_size: int = 800_000\n",
    "    min_buffer_size: int = 20_000\n",
    "    grad_clip: float = 5.0\n",
    "    double_dqn: bool = True\n",
    "    dueling: bool = True\n",
    "    prioritized_replay: bool = True\n",
    "    per_alpha: float = 0.6\n",
    "    per_beta_start: float = 0.4\n",
    "    per_beta_end: float = 1.0\n",
    "    per_beta_steps: int = 1_200_000\n",
    "    n_step: int = 3\n",
    "    distributional_c51: bool = True\n",
    "    atoms: int = 51\n",
    "    v_min: float = -20.0\n",
    "    v_max: float = 20.0\n",
    "    noisy_nets: bool = False\n",
    "    target_update_interval: int = 15_000\n",
    "    tau: float | None = None\n",
    "    device: str = \"cpu\"\n",
    "\n",
    "    def to_agent(self):\n",
    "        from blackjackai_rl.agents import DQNConfig\n",
    "        return DQNConfig(**asdict(self))\n",
    "\n",
    "@dataclass\n",
    "class NotebookTrainingConfig:\n",
    "    vector_envs: int = 32\n",
    "    training_steps: int = 2_000_000\n",
    "    log_interval: int = 2_000\n",
    "    evaluation_hands: int = 100_000\n",
    "    seed: int = 2024\n",
    "    output_root: Path = Path(\"runs\")\n",
    "\n",
    "\n",
    "env_config = NotebookEnvConfig()\n",
    "agent_config = NotebookAgentConfig()\n",
    "training_config = NotebookTrainingConfig()\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"Environment config:\")\n",
    "pprint(asdict(env_config))\n",
    "print(\"\n",
    "Agent config:\")\n",
    "pprint(asdict(agent_config))\n",
    "print(\"\n",
    "Training config:\")\n",
    "pprint(asdict(training_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e1d08",
   "metadata": {},
   "source": [
    "### Field guide\n",
    "\n",
    "* **EnvConfig** controls table rules, deck penetration, bankroll bounds, and betting spread.\n",
    "* **AgentConfig** toggles Rainbow DQN components (dueling heads, PER, C51, etc.) and optimizer hyperparameters.\n",
    "* **TrainingConfig** governs vectorised environment count, total frames, logging cadence, evaluation horizon, and reproducibility seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f046ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def setup_environment():\n",
    "    import subprocess\n",
    "    import sys\n",
    "    print(\"Installing blackjackai in editable mode‚Ä¶\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"], check=True)\n",
    "\n",
    "if not RUN_ALL:\n",
    "    setup_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def set_reproducibility():\n",
    "    import random\n",
    "    import numpy as np\n",
    "    seed = training_config.seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    except ImportError:\n",
    "        torch = None\n",
    "    print(f\"Seeds initialised to {seed}\")\n",
    "    return seed\n",
    "\n",
    "if not RUN_ALL:\n",
    "    set_reproducibility()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def environment_sanity_checks():\n",
    "    from blackjackai_rl.env import BlackjackEnv\n",
    "    env = BlackjackEnv(env_config.to_env())\n",
    "    obs, info = env.reset()\n",
    "    print(\"Initial observation shape:\", obs.shape)\n",
    "    print(\"Initial legal actions:\", [env.action_names[a] for a in info[\"legal_actions\"]])\n",
    "    print(\"Action mask:\", info[\"action_mask\"])\n",
    "    obs_play, _, _, info_play = env.step(0)\n",
    "    print(\"Play phase mask:\", info_play[\"action_mask\"])\n",
    "    env.step(env.ACTION_STAND)\n",
    "\n",
    "if not RUN_ALL:\n",
    "    environment_sanity_checks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9acf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def run_training():\n",
    "    from blackjackai_rl.training import train_rainbow\n",
    "    print(\"Starting training‚Ä¶\")\n",
    "    results = train_rainbow(\n",
    "        env_config.to_env(),\n",
    "        agent_config.to_agent(),\n",
    "        training_config.training_steps,\n",
    "        vector_envs=training_config.vector_envs,\n",
    "        log_interval=training_config.log_interval,\n",
    "        output_dir=training_config.output_root,\n",
    "    )\n",
    "    globals()[\"TRAINING_RESULTS\"] = results\n",
    "    print(\"Best checkpoint:\", results[\"best_model_path\"])\n",
    "\n",
    "if not RUN_ALL:\n",
    "    run_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def run_evaluation():\n",
    "    from blackjackai_rl.agents import RainbowDQNAgent\n",
    "    from blackjackai_rl.evaluation import evaluate_agent\n",
    "    agent = RainbowDQNAgent(agent_config.to_agent())\n",
    "    best_path = TRAINING_RESULTS.get(\"best_model_path\")\n",
    "    if best_path:\n",
    "        agent.load(best_path)\n",
    "    results = evaluate_agent(\n",
    "        agent,\n",
    "        env_config.to_env(),\n",
    "        training_config.evaluation_hands,\n",
    "        training_config.output_root,\n",
    "        training_history=TRAINING_RESULTS,\n",
    "    )\n",
    "    globals()[\"EVALUATION_RESULTS\"] = results\n",
    "    print(\"Evaluation artifacts saved to:\", results[\"run_dir\"])\n",
    "    from IPython.display import Image, display\n",
    "    for name, path in results[\"plots\"].items():\n",
    "        display(Image(filename=path))\n",
    "\n",
    "if not RUN_ALL:\n",
    "    run_evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def show_summary():\n",
    "    from IPython.display import Markdown, display\n",
    "    metrics = EVALUATION_RESULTS.get(\"metrics\", {})\n",
    "    if not metrics:\n",
    "        print(\"No evaluation metrics available yet.\")\n",
    "        return\n",
    "    summary = (\n",
    "        f\"### Evaluation snapshot\n",
    "\n",
    "\"\n",
    "        f\"* EV/100 hands: {metrics['ev_per_100']:.3f}\n",
    "\"\n",
    "        f\"* 95% CI: {metrics['ev_confidence'][0]:.3f} ‚Äì {metrics['ev_confidence'][1]:.3f}\n",
    "\"\n",
    "        f\"* Win rate: {metrics['win_rate']:.2%}\n",
    "\"\n",
    "        f\"* Loss rate: {metrics['loss_rate']:.2%}\n",
    "\"\n",
    "        f\"* Push rate: {metrics['push_rate']:.2%}\n",
    "\"\n",
    "        f\"* Bust rate: {metrics['bust_rate']:.2%}\n",
    "\n",
    "\"\n",
    "        f\"Summary file: `{EVALUATION_RESULTS['summary_path']}`\"\n",
    "    )\n",
    "    display(Markdown(summary))\n",
    "\n",
    "if not RUN_ALL:\n",
    "    show_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def baseline_appendix():\n",
    "    baselines = EVALUATION_RESULTS.get(\"metrics\", {}).get(\"baselines\", {})\n",
    "    if not baselines:\n",
    "        print(\"Baseline metrics unavailable.\")\n",
    "        return\n",
    "    print(\"Baseline EV/100 comparison:\")\n",
    "    for name, data in baselines.items():\n",
    "        print(f\"  {name}: {data.get('ev_per_100', 0.0):.3f}\")\n",
    "\n",
    "if not RUN_ALL:\n",
    "    baseline_appendix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b419bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_step\n",
    "def quick_smoke_evaluation():\n",
    "    from blackjackai_rl.agents import RainbowDQNAgent\n",
    "    from blackjackai_rl.env import BlackjackEnv\n",
    "    import numpy as np\n",
    "    agent = RainbowDQNAgent(agent_config.to_agent())\n",
    "    best_path = TRAINING_RESULTS.get(\"best_model_path\")\n",
    "    if best_path:\n",
    "        agent.load(best_path)\n",
    "    env = BlackjackEnv(env_config.to_env())\n",
    "    obs, info = env.reset()\n",
    "    total_reward = 0.0\n",
    "    for _ in range(10):\n",
    "        action = agent.select_actions(obs[np.newaxis, :], [info], deterministic=True)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            obs, info = env.reset()\n",
    "    print(\"10-hand smoke reward:\", total_reward)\n",
    "\n",
    "if not RUN_ALL:\n",
    "    quick_smoke_evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ceb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ALL:\n",
    "    run_all_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
